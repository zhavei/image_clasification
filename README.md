# Rock, Paper, Scissors Image Classification

## Overview
This repository contains code for an image classification project focusing on the Rock, Paper, Scissors dataset. The project aims to create a model capable of accurately classifying images of hands showing rock, paper, or scissors signs.

## Dataset
The dataset used in this project is the rockpaperscissors dataset. You can download it using the following link: [rockpaperscissors.zip](https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip). The dataset is divided into a training set and a validation set. The validation set constitutes 40% of the total dataset, with 1314 samples for training and 874 samples for validation.

## Implementation Details
- Image augmentation techniques have been applied to enhance model robustness.
- ImageDataGenerator is utilized for efficient image loading and preprocessing.
- The model architecture follows a sequential structure.
- The training process should not exceed 30 minutes.
- The model must achieve a minimum accuracy of 85%.
- The model incorporates more than one hidden layer.
- Adam optimizer and categorical_crossentropy loss function are employed.

## Execution Environment
The entire project is developed in Google Colaboratory (Colab), ensuring ease of access and reproducibility.

## How to Use
1. Download the rockpaperscissors dataset from the provided link.
2. Upload the dataset to your Colab environment or set the correct path.
3. Run the provided notebook for training and evaluation.
4. Experiment with hyperparameters or model architecture to enhance performance.

## Contributors
- [[muhamad syafe'ie](https://github.com/zhavei)]

Feel free to contribute, report issues, or suggest improvements. Happy coding!
